#                                                #
# @file:    intfc_post_tagger.py
# @author:    shicq@cs.brandeis.edu
# @brief:   test post tagger using naive bayes
#                                                #
 
import sys,os,time,nltk, cPickle as pickle

intfc = __import__(intfc_common_io)


##
#    
#    @brief:    finding out what the most common suffixes
##

from nltk.corpus import brown
suffix_fdist = nltk.FreqDist()
for word in brown.words():
     word = word.lower()
     suffix_fdist.inc(word[-1:])
     suffix_fdist.inc(word[-2:])
     suffix_fdist.inc(word[-3:])

common_suffixes = suffix_fdist.keys()[:100]
print common_suffixes
log("common_suffixes")

##
#    
#    @brief:    define a feature extractor function which checks a given word for these suffixes
##
def pos_features(word):
    features = {}
    for suffix in common_suffixes:
        features['endswith(%s)' % suffix] = word.lower().endswith(suffix)
    return features
log("def pos_features")

##
#    
#    @brief:     defined our feature extractor, we can use it to train a new "decision tree" classifier
##
# tagged_words = brown.tagged_words(categories='news')
# featuresets = [(pos_features(n), g) for (n,g) in tagged_words]
# log("featuresets")
# 
# dump(featuresets, '/home/j/llc/shicq/Project/chunqishi/lapps/edu.brandeis.cs.nltk-web-service/src/main/resources/pythons', 'featuresets')
# log("dump featuresets")

featuresets = load('/home/j/llc/shicq/Project/chunqishi/lapps/edu.brandeis.cs.nltk-web-service/src/main/resources/pythons', 'featuresets')
log("load featuresets")

 
size = int(len(featuresets) * 0.1)
# train_set, test_set = featuresets[size:], featuresets[:size]

train_set, test_set = featuresets[1:200], featuresets[201:400]
log("train_set")
 
classifier = nltk.DecisionTreeClassifier.train(train_set)
log("classifier")
print nltk.classify.accuracy(classifier, test_set)
log("accuracy")

print classifier.classify(pos_features('cats'))
log("classify")




#sys.path.append('./') 
#code_suffix_pos_tag=__import__('code_suffix_pos_tag')
#code_consecutive_pos_tagger=__import__('code_consecutive_pos_tagger')


# tagged_sents = brown.tagged_sents(categories='news')
# size = int(len(tagged_sents) * 0.1)
# train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]
# tagger = ConsecutivePosTagger(train_sents)
# print tagger.evaluate(test_sents)

#pos_features()
#code_suffix_pos_tag = input('code_suffix_pos_tag.py')
#print code_suffix_pos_tag
#pm = __import__(code_suffix_pos_tag)
#print pm